{"cells": [{"cell_type": "code", "execution_count": 2, "id": "52f3ccf4-4743-4cee-85b7-214cb2505279", "metadata": {"tags": []}, "outputs": [], "source": "import org.apache.spark.sql.functions.{explode, split, col}\nimport spark.implicits._"}, {"cell_type": "code", "execution_count": 1, "id": "67484aca-76c2-4070-8fc5-6ecd3f4ea683", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "spark = org.apache.spark.sql.SparkSession@2a56f541\nsparkConext = org.apache.spark.SparkContext@48bababb\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "org.apache.spark.SparkContext@48bababb"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "// Creating the Spark Context\nval spark = SparkSession.builder().appName(\"Movie Ratings DataSet\").master(\"local[*]\").getOrCreate()\nval sparkConext = spark.sparkContext"}, {"cell_type": "code", "execution_count": 3, "id": "68232a87-1874-4e35-9382-10786a0d38f2", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "moviesDffPath = gs://artifacts_spark_jobs/movie.csv\nratingDffPath = gs://artifacts_spark_jobs/rating.csv\nmoviesDff = [movieId: int, title: string ... 1 more field]\nratingsDff = [userId: int, movieId: int ... 2 more fields]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[userId: int, movieId: int ... 2 more fields]"}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "val moviesDffPath = \"gs://artifacts_spark_jobs/movie.csv\"\nval ratingDffPath = \"gs://artifacts_spark_jobs/rating.csv\"\n\n\nval moviesDff = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(moviesDffPath)\nval ratingsDff = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(ratingDffPath)\n\n// reading the csv files from source"}, {"cell_type": "code", "execution_count": 6, "id": "c0b103db-9c26-4d41-9578-a8ec596a8372", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "explodedGenresDF = [movieId: int, title: string ... 1 more field]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[movieId: int, title: string ... 1 more field]"}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": "val explodedGenresDF = moviesDff.withColumn(\"genres\", explode(split(col(\"genres\"),\"\\\\|\"))).select(\"movieId\",\"title\",\"genres\")"}, {"cell_type": "code", "execution_count": 7, "id": "a8103238-e85b-4c3d-8760-5e352037659f", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "moviesRDD = MapPartitionsRDD[25] at rdd at <console>:29\nstandarizedData = MapPartitionsRDD[26] at map at <console>:41\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "standardizeGenre: (genre: String)String\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "MapPartitionsRDD[26] at map at <console>:41"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "val moviesRDD = explodedGenresDF.rdd\n\ndef standardizeGenre(genre: String): String ={\n  genre match{\n    case \"Sci-Fi\" => \"Science Fiction\"\n    case \"Film-Noir\" => \"Black and White\"\n    case \"(no genres listed)\" => \"Others\"\n    case _ => genre \n  }\n}\n\n\nval standarizedData = moviesRDD.map(eachEle=>{\n   val movieId = eachEle.getAs[Int](\"movieId\")\n   val movieName = eachEle.getAs[String](\"title\")\n   val genre = eachEle.getAs[String](\"genres\")\n\n   val standardizedGenre = standardizeGenre(genre)\n  \n   (movieId, (movieName, standardizedGenre)) \n})"}, {"cell_type": "code", "execution_count": 8, "id": "897de494-aac8-4ffd-91bd-e634159db5d2", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "ratingsRDD = MapPartitionsRDD[32] at map at <console>:29\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "MapPartitionsRDD[32] at map at <console>:29"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": "val ratingsRDD = ratingsDff.rdd.map(row => {\n  val movieId = row.getAs[Int](\"movieId\")\n  val rating = row.getAs[Double](\"rating\")\n  (movieId, rating)  // Restructured for join\n})"}, {"cell_type": "code", "execution_count": 9, "id": "5231aa4d-32ee-458f-a854-c14d9c038c17", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "moviesWithRatings = MapPartitionsRDD[35] at join at <console>:30\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "MapPartitionsRDD[35] at join at <console>:30"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": "val moviesWithRatings = ratingsRDD.join(standarizedData)"}, {"cell_type": "code", "execution_count": 10, "id": "66b082f5-8d7d-44a8-8745-4a8b394fee5b", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "genreAverageRatings = MapPartitionsRDD[38] at mapValues at <console>:36\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "MapPartitionsRDD[38] at mapValues at <console>:36"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "val genreAverageRatings = moviesWithRatings\n  .map { case (_, (rating, (_, genre))) => \n    (genre, (rating, 1))\n  }\n  .reduceByKey { case ((sum1, count1), (sum2, count2)) => \n    (sum1 + sum2, count1 + count2)  \n  }\n  .mapValues { case (sum, count) => \n    sum / count.toDouble  \n  }"}, {"cell_type": "code", "execution_count": 11, "id": "5c5b8333-9626-4859-8429-c72c706d6b45", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "genreAverageDF = [genre: string, average_rating: double]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[genre: string, average_rating: double]"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": "val genreAverageDF = genreAverageRatings.toDF(\"genre\", \"average_rating\")"}, {"cell_type": "code", "execution_count": 12, "id": "bbfa625f-cb4e-4378-97d7-e1ec8d2aefcc", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "hdfsPath = hdfs:/user/hdfs/CaseStudies\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "hdfs:/user/hdfs/CaseStudies"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "val hdfsPath = \"hdfs:/user/hdfs/CaseStudies\""}, {"cell_type": "code", "execution_count": null, "id": "50e8ec5d-4238-42c0-808e-2592f4ea954e", "metadata": {"tags": []}, "outputs": [], "source": "genreAverageDF.write.mode(\"overwrite\").parquet(hdfsPath)"}, {"cell_type": "code", "execution_count": null, "id": "62e0188c-a329-46d9-9053-f66cf6ac11f2", "metadata": {"tags": []}, "outputs": [], "source": "val checkDF = spark.read.parquet(hdfsPath)\ncheckDF.show()"}, {"cell_type": "code", "execution_count": null, "id": "edb17e93-d29f-4f7b-bc1f-2cafc5b815fb", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Apache Toree - Scala", "language": "scala", "name": "apache_toree_scala"}, "language_info": {"codemirror_mode": "text/x-scala", "file_extension": ".scala", "mimetype": "text/x-scala", "name": "scala", "pygments_lexer": "scala", "version": "2.12.15"}}, "nbformat": 4, "nbformat_minor": 5}